# Cache

## Cache

자주 필요한 데이터나 계산된 결과 값의 **복사본**을 일시적으로 저장하기 위해 사용하는 곳

- 저장한 데이터를 사용해 전체적인 처리 속도를 향상시킨다.

- 복사본을 사용하기 때문에 원본과 달라지는 경우가 있다.

  - 일관성 유지에 유의하여야 한다.

- 운영체제, CDN, DNS 등의 네트쿼크 계층, 웹 애플리케이션 및 데이터베이스를 비롯한 다양한 기술 계층에 걸쳐 활용된다.

다음과 같은 경우에 사용할 수 있다.

- 데이터에 직접적으로 접근하는 데 걸리는 시간이 오래 걸릴 때

- 필요한 값을 얻기 위해 계산하는 과정을 생략하고 싶을 때

- 반복적으로 동일한 결과를 돌려줄 때(이미지, 썸네일 등)

## 캐시의 존재 이유

CPU는 데이터 처리를 위해 메모리와 끊임없이 데이터를 주고받는데,

메모리가 CPU의 데이터 처리 속도를 쫓아가지 못한다.

- CPU가 메모리를 기다려야 하는 병목 현상이 발생한다.

  - 따라서 병목현상을 완화하기 위해 CPU와 메인 메모리 사이에 크기는 작지만 속도가 빠른 캐시 메모리를 둔다.

  - 재사용 가능성이 높은 데이터 복사본을 저장해둔 뒤 CPU가 요청하는 데이터를 바로 전달한다.

## 메인 메모리와 캐시 메모리의 차이

메인 메모리

- 한 셀당 트랜지스터 1개의 DRAM을 사용한다.

캐시 메모리

- 한 셀당 트랜지스터 6개의 SRAM을 사용한다.

- 캐시 메모리가 메인 메모리보다 더 비싸다.

크고 느린 메인 메모리와 작고 빠른 캐시 메모리의 장점을 조합하여 크고 빠른 메모리처럼 행동하도록 만든다.

## 데이터 지역성

데이터 접근이 시간적 또는 공간적으로 가깝게 일어나는 것을 의미한다.

- 시간적 지역성

  - 한 번 참조된 변수는 가까운 미래에 또 참조될 가능성이 높다.

  - 메모리 상의 같은 주소에 여러 번 읽기 쓰기를 수행할 경우 상대적으로 작은 크기의 캐시를 사용해도 효율성을 높일 수 있다.

  - for, while 문의 조건 변수 i

- 공간적 지역성

  - 한 메모리 주소에 접근할 때 그 주소뿐 아니라 해당 블록을 전부 캐시에 가져온다.

    - 어떤 데이터에 접근할 때, 그 데이터 근처에 있는 다른 데이터도 참조될 가능성이 높다.

  - 특정 데이터와 가까운 주소가 순서대로 접근되는 경우

    - 메모리 주소를 오름차순이나 내림차순으로 접근한다면, 캐시에 이미 저장된 같은 블록의 데이터에 접근하게 된다.

      - 캐시의 효율성이 크게 향상될 수 있다.

    - 배열은 순서대로 접근할 가능성이 높다.

## 캐시 히트와 캐시 미스

캐시 메모리가 해당 데이터를 가지고 있다면 **캐시 히트**

- 데이터를 변경할 주소가 캐싱된 상태라면 메인 메모리의 데이터를 업데이트 하는 대신 캐시의 데이터가 업데이트된다.

  - 메인 메모리의 데이터를 업데이트해야 하는데, 그 방식은 Write Through 정책과 Write Back 정책으로 나뉜다.

해당 데이터가 없어서 메인 메모리에서 가져와야 한다면 **캐시 미스**

- 일반적으로 캐시 미스가 발생하면 캐싱을 한다.

## Write Through

데이터가 변경되면 메인 메모리를 바로 업데이트 한다.

단순하고 캐시와 메인 메모리의 일관성을 유지할 수 있지만, 매번 바꾸어야 하므로 느리다.

## Write Back

캐시의 데이터만 업데이트 하다가, 업데이트 된 데이터가 캐시에서 빠질 때 메인 메모리를 업데이트한다.

속도가 빠르지만, 캐시와 메모리가 서로 값이 다른 경우가 발생할 수 있다.

- 데이터가 변경됐는지 확인하기 위해 캐시 블록마다 dirty 비트를 추가해야 한다.

  - 데이터가 변경되었다면 dirty 비트를 1로 바꾼다.

  - 해당 블록이 교체될 때 dirty 비트가 1이라면 메인 메모리의 데이터를 변경한다.
